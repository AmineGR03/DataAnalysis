\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}

% Configuration de la page
\geometry{margin=2.5cm}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{Chapitre 6}
\fancyfoot[C]{\thepage}

% Configuration des titres
\titleformat{\section}
{\Large\bfseries\color{blue!70!black}}
{}
{0em}
{}[\titlerule]

\titleformat{\subsection}
{\large\bfseries\color{blue!50!black}}
{}
{0em}
{}

\titleformat{\subsubsection}
{\normalsize\bfseries}
{}
{0em}
{}

% Commandes personnalisées
\newcommand{\R}{\mathbb{R}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}

% Métadonnées
\title{Résumé Complet - Chapitre 6\\
\large Analyse en Composantes Principales (ACP)}
\author{AmineGR03}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Définition et Objectifs}

\subsection{Définition}

L'\textbf{Analyse en Composantes Principales (ACP)} est :
\begin{itemize}
    \item Une méthode descriptive multidimensionnelle
    \item Un outil statistique de \textbf{synthèse de l'information}
    \item Une méthode factorielle permettant d'analyser des tableaux de données quantitatives
\end{itemize}

\subsection{Objectifs}

L'ACP permet d'étudier :
\begin{enumerate}
    \item \textbf{La variabilité entre les individus} : différences et ressemblances
    \item \textbf{Les liaisons entre les variables} : groupes de variables corrélées, nouvelles variables synthétiques
\end{enumerate}

\subsection{Problème géométrique}

\begin{itemize}
    \item Le nuage de points des données s'inscrit dans un espace de \textbf{$p$ dimensions}
    \item Chaque point représente un individu par rapport à $x_1, x_2, \ldots, x_p$
    \item Il est difficile de visualiser les relations dès que $p > 3$
\end{itemize}

\textbf{Solution} : Projeter le nuage sur des plans de dimension réduite (2D ou 3D) tout en conservant le maximum d'information.

\newpage

\section{Notations et Définitions}

\subsection{Matrice des données}

Soit $n$ individus caractérisés par $p$ variables quantitatives. Les données sont présentées dans une \textbf{matrice des données} de dimension $n \times p$ :

\begin{align}
\mathbf{X} = \begin{pmatrix}
x_{11} & x_{12} & \cdots & x_{1j} & \cdots & x_{1p} \\
x_{21} & x_{22} & \cdots & x_{2j} & \cdots & x_{2p} \\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
x_{i1} & x_{i2} & \cdots & x_{ij} & \cdots & x_{ip} \\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} & \cdots & x_{nj} & \cdots & x_{np}
\end{pmatrix}
\end{align}

\subsection{Individus et variables}

\begin{itemize}
    \item \textbf{Individu} $e_i$ : vecteur de $\R^p$ défini par $e_i^\top = (x_{i1}, x_{i2}, \ldots, x_{ip})$
    \item \textbf{Nuage des individus} : ensemble des vecteurs $e_i, i = 1, \ldots, n$
    \item \textbf{Variable} $X_k$ : vecteur de $\R^n$ défini par $X_k^\top = (x_{1k}, x_{2k}, \ldots, x_{nk})$
    \item \textbf{Nuage des variables} : ensemble des vecteurs $X_k, k = 1, \ldots, p$
\end{itemize}

\subsection{Centre de gravité}

Le vecteur individu moyen (centre de gravité) est :

\begin{align}
\mathbf{g}^\top = (\bar{x}_1, \bar{x}_2, \ldots, \bar{x}_p)
\end{align}

où $\bar{x}_j = \frac{1}{n}\sum_{i=1}^{n} x_{ij}$ est la moyenne de la variable $X_j$.

\newpage

\section{Centrage et Réduction}

\subsection{Nécessité}

Les $p$ variables sont de nature différente. Pour \textbf{homogénéiser les unités}, les variables doivent être \textbf{centrées et réduites}.

\subsection{Définition}

Une variable est \textbf{centrée et réduite} si :
\begin{itemize}
    \item Sa moyenne est nulle : $\bar{X} = 0$
    \item Sa variance est égale à 1 : $\Var(X) = 1$
\end{itemize}

\subsection{Matrice centrée réduite}

La matrice centrée réduite $\mathbf{M}_{cr} = (m_{ij})_{1 \leq i \leq n, 1 \leq j \leq p}$ est obtenue par :

\begin{align}
m_{ij} &= \frac{x_{ij} - \bar{x}_j}{\sigma_j} \\
\sigma_j &= \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_{ij} - \bar{x}_j)^2}
\end{align}

où :
\begin{itemize}
    \item $\bar{x}_j$ : moyenne de la variable $X_j$
    \item $\sigma_j$ : écart-type de la variable $X_j$
\end{itemize}

\subsection{Matrice centrée}

La matrice centrée $\mathbf{M}_c = (a_{ij})$ est obtenue par :

\begin{align}
a_{ij} = x_{ij} - \bar{x}_j
\end{align}

\newpage

\section{Matrices de Variance-Covariance et de Corrélation}

\subsection{Matrice des variances-covariances}

\subsubsection{Définition}

\begin{align}
\mathbf{V} = \begin{pmatrix}
\Var(X_1) & \Cov(X_1, X_2) & \cdots & \Cov(X_1, X_p) \\
\Cov(X_2, X_1) & \Var(X_2) & \cdots & \Cov(X_2, X_p) \\
\vdots & \vdots & \ddots & \vdots \\
\Cov(X_p, X_1) & \Cov(X_p, X_2) & \cdots & \Var(X_p)
\end{pmatrix}
\end{align}

\subsubsection{Calcul}

\begin{align}
\mathbf{V} = \frac{1}{n} \mathbf{M}_c^T \mathbf{M}_c
\end{align}

où $\mathbf{M}_c^T$ est la transposée de la matrice centrée.

\subsubsection{Propriétés}

\begin{itemize}
    \item Si $\Cov(X_i, X_j) = 0$ : les variables $X_i$ et $X_j$ sont indépendantes (linéairement)
    \item Si $\Cov(X_i, X_j) \neq 0$ : les variables $X_i$ et $X_j$ sont dépendantes (relation linéaire)
\end{itemize}

\subsection{Matrice des corrélations}

\subsubsection{Définition}

La matrice des corrélations entre variables permet d'analyser les relations bilatérales entre les variables.

\subsubsection{Calcul}

\begin{align}
\mathbf{U} = \frac{1}{n} \mathbf{M}_{cr}^T \mathbf{M}_{cr}
\end{align}

où $\mathbf{M}_{cr}^T$ est la transposée de la matrice centrée réduite.

\subsubsection{Propriétés}

\begin{itemize}
    \item $\mathbf{U}$ est une matrice symétrique
    \item Les éléments diagonaux valent 1 (corrélation d'une variable avec elle-même)
    \item Les éléments hors diagonale sont les coefficients de corrélation de Pearson entre variables
\end{itemize}

\newpage

\section{Notion d'Inertie}

\subsection{Définition}

L'\textbf{inertie} du nuage des individus par rapport à son centre de gravité mesure la variabilité (dispersion) des données.

\subsection{Calcul}

\begin{align}
I_g = \frac{1}{n}\sum_{i=1}^{n}\sum_{k=1}^{p}(x_{ik} - \bar{x}_k)^2 = \sum_{k=1}^{p} \sigma_k^2
\end{align}

\subsection{Cas des données centrées-réduites}

Si les données sont centrées et réduites :
\begin{itemize}
    \item $I_g = p$
    \item $\mathbf{g}^\top = (0, 0, \ldots, 0)$
\end{itemize}

\textbf{Dans la suite, on suppose que les données ont été centrées et réduites.}

\newpage

\section{Démarche de l'ACP}

\subsection{Étapes principales}

\begin{enumerate}
    \item \textbf{Centrage et réduction} des données
    \item \textbf{Déterminer les valeurs propres et vecteurs propres} de la matrice de corrélation $\mathbf{U}$
    \item \textbf{Déterminer les axes factoriels}
    \item \textbf{Sélectionner les composantes principales}
\end{enumerate}

\newpage

\section{Valeurs Propres et Vecteurs Propres}

\subsection{Polynôme caractéristique}

Pour trouver les valeurs propres de $\mathbf{U}$, on résout :

\begin{align}
P(\lambda) = \det(\mathbf{U} - \lambda \mathbf{I}_p) = 0
\end{align}

où $\mathbf{I}_p$ est la matrice identité de dimension $p \times p$.

\subsection{Valeurs propres}

Les valeurs propres $\lambda_1, \lambda_2, \ldots, \lambda_p$ sont ordonnées par ordre décroissant :

\begin{align}
\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_p \geq 0
\end{align}

\subsection{Vecteurs propres}

Pour chaque valeur propre $\lambda_k$, on trouve le vecteur propre associé $\mathbf{u}_k$ tel que :

\begin{align}
\mathbf{U}\mathbf{u}_k = \lambda_k \mathbf{u}_k
\end{align}

Les vecteurs propres sont \textbf{orthonormés} (orthogonaux et de norme 1).

\newpage

\section{Axes Factoriels et Composantes Principales}

\subsection{Axes principaux d'inertie}

Les \textbf{axes principaux d'inertie} sont les axes de direction des vecteurs propres de $\mathbf{U}$ normés à 1.

\begin{itemize}
    \item \textbf{Axe 1} : associé à la plus grande valeur propre $\lambda_1$, noté $\mathbf{u}_1$
    \item \textbf{Axe 2} : associé à la deuxième valeur propre $\lambda_2$, noté $\mathbf{u}_2$
    \item $\ldots$
    \item \textbf{Axe $p$} : associé à la valeur propre $\lambda_p$, noté $\mathbf{u}_p$
\end{itemize}

\subsection{Composantes principales}

À chaque axe est associée une variable appelée \textbf{composante principale}.

\begin{itemize}
    \item \textbf{Composante $C_1$} : vecteur contenant les coordonnées des projections des individus sur l'axe 1
    \item \textbf{Composante $C_2$} : vecteur contenant les coordonnées des projections des individus sur l'axe 2
    \item $\ldots$
\end{itemize}

\subsubsection{Calcul}

\begin{align}
\mathbf{C}_1 &= \mathbf{M}_{cr} \mathbf{u}_1 \\
\mathbf{C}_2 &= \mathbf{M}_{cr} \mathbf{u}_2 \\
&\vdots \\
\mathbf{C}_k &= \mathbf{M}_{cr} \mathbf{u}_k
\end{align}

\subsection{Propriétés des composantes principales}

\begin{enumerate}
    \item \textbf{Centrées} : la moyenne de chaque composante est nulle
    \item \textbf{Variance} : la variance de la composante $C_k$ est égale à la valeur propre $\lambda_k$
    \item \textbf{Non corrélées} : les composantes principales sont deux à deux non corrélées
\end{enumerate}

\newpage

\section{Inertie Expliquée}

\subsection{Définition}

L'\textbf{inertie expliquée} par un axe principal mesure la quantité d'information contenue dans cet axe.

\subsection{Calcul}

\begin{align}
\text{Inertie axe } k = \frac{\lambda_k}{\sum_{i=1}^{p} \lambda_i} = \frac{\lambda_k}{I_g}
\end{align}

Pour des données centrées-réduites, $I_g = p$, donc :

\begin{align}
\text{Inertie axe } k = \frac{\lambda_k}{p}
\end{align}

\subsection{Inertie cumulée}

L'inertie cumulée des $k$ premiers axes est :

\begin{align}
\text{Inertie cumulée} = \frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{p} \lambda_i}
\end{align}

\subsection{Interprétation}

\begin{itemize}
    \item Plus l'inertie expliquée est élevée, plus l'axe contient d'information
    \item On retient généralement les axes qui expliquent au moins 70-80\% de l'inertie totale
\end{itemize}

\newpage

\section{Contributions}

\subsection{Contribution des individus à l'inertie}

La contribution de l'individu $i$ à l'inertie totale est :

\begin{align}
\text{CONTR}(i) = \frac{1}{n} \sum_{j=1}^{p} \frac{m_{ij}^2}{I_g}
\end{align}

où $m_{ij}$ est l'élément de la matrice centrée réduite $\mathbf{M}_{cr}$.

Pour des données centrées-réduites ($I_g = p$) :

\begin{align}
\text{CONTR}(i) = \frac{1}{np} \sum_{j=1}^{p} m_{ij}^2
\end{align}

\subsection{Contribution des variables}

La contribution de la variable $X_j$ à l'inertie totale est :

\begin{align}
\text{CONTR}(X_j) = \frac{1}{p} \sum_{i=1}^{n} \frac{m_{ij}^2}{I_g}
\end{align}

\subsection{Contribution des individus à la construction des axes}

La contribution de l'individu $i$ à la construction de l'axe $k$ est :

\begin{align}
\text{CONTR}(i, \text{axe } k) = \frac{1}{n} \frac{C_{ik}^2}{\lambda_k}
\end{align}

où $C_{ik}$ est la coordonnée de l'individu $i$ sur la composante principale $C_k$.

\newpage

\section{Résumé des Formules Clés}

\subsection{Matrices}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Matrice} & \textbf{Formule} \\
\hline
Centrée & $a_{ij} = x_{ij} - \bar{x}_j$ \\
\hline
Centrée réduite & $m_{ij} = \frac{x_{ij} - \bar{x}_j}{\sigma_j}$ \\
\hline
Variances-covariances & $\mathbf{V} = \frac{1}{n}\mathbf{M}_c^T\mathbf{M}_c$ \\
\hline
Corrélations & $\mathbf{U} = \frac{1}{n}\mathbf{M}_{cr}^T\mathbf{M}_{cr}$ \\
\hline
\end{tabular}
\end{table}

\subsection{Valeurs et vecteurs propres}

\begin{align}
\mathbf{U}\mathbf{u}_k = \lambda_k \mathbf{u}_k, \quad k = 1, \ldots, p
\end{align}

\subsection{Composantes principales}

\begin{align}
\mathbf{C}_k = \mathbf{M}_{cr} \mathbf{u}_k
\end{align}

\subsection{Inertie}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Concept} & \textbf{Formule} \\
\hline
Inertie totale & $I_g = \sum_{k=1}^{p} \sigma_k^2 = p$ (si centré-réduit) \\
\hline
Inertie axe $k$ & $\frac{\lambda_k}{\sum_{i=1}^{p} \lambda_i}$ \\
\hline
Inertie cumulée & $\frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{p} \lambda_i}$ \\
\hline
\end{tabular}
\end{table}

\subsection{Contributions}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Type} & \textbf{Formule} \\
\hline
Individu $i$ & $\text{CONTR}(i) = \frac{1}{np}\sum_{j=1}^{p} m_{ij}^2$ \\
\hline
Variable $X_j$ & $\text{CONTR}(X_j) = \frac{1}{p}\sum_{i=1}^{n} \frac{m_{ij}^2}{I_g}$ \\
\hline
Individu $i$ à l'axe $k$ & $\text{CONTR}(i, \text{axe } k) = \frac{1}{n}\frac{C_{ik}^2}{\lambda_k}$ \\
\hline
\end{tabular}
\end{table}

\newpage

\section{Opérations sur Matrices (Rappels)}

\subsection{Multiplication matricielle}

Pour $\mathbf{A}$ ($m \times n$) et $\mathbf{B}$ ($n \times p$) :

\begin{align}
(\mathbf{AB})_{ij} = \sum_{k=1}^{n} a_{ik}b_{kj}
\end{align}

\subsection{Transposée}

\begin{align}
(\mathbf{A}^T)_{ij} = a_{ji}
\end{align}

\subsection{Propriétés importantes}

\begin{itemize}
    \item $(\mathbf{AB})^T = \mathbf{B}^T\mathbf{A}^T$
    \item $(\mathbf{A}^T)^T = \mathbf{A}$
    \item Si $\mathbf{A}$ est symétrique : $\mathbf{A}^T = \mathbf{A}$
\end{itemize}

\subsection{Déterminant}

\subsubsection{Matrice 2×2}

\begin{align}
\det(\mathbf{A}) = \begin{vmatrix} a & b \\ c & d \end{vmatrix} = ad - bc
\end{align}

\subsubsection{Matrice 3×3}

\begin{align}
\det(\mathbf{A}) = a(ei - fh) - b(di - fg) + c(dh - eg)
\end{align}

\newpage

\section{Exercice d'Application}

\subsection{Énoncé}

Une étude porte sur 4 pays (A, B, C, D) caractérisés par 3 variables économiques :
\begin{itemize}
    \item $X_1$ : Investissements directs étrangers (IDE) en millions d'euros
    \item $X_2$ : Taux de croissance économique (\%)
    \item $X_3$ : Taux d'inflation (\%)
\end{itemize}

\textbf{Tableau des données} :

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Pays} & \textbf{IDE ($X_1$)} & \textbf{Taux croissance ($X_2$)} & \textbf{Taux inflation ($X_3$)} \\
\hline
A & 300 & 2 & 6 \\
\hline
B & 450 & 2 & 4 \\
\hline
C & 950 & 8 & 2 \\
\hline
D & 700 & 7 & 5 \\
\hline
\end{tabular}
\end{table}

\textbf{Travail à faire} :

\begin{enumerate}
    \item Calculer la moyenne et l'écart-type de chaque variable.
    \item Déterminer la matrice centrée réduite $\mathbf{M}_{cr}$.
    \item Déterminer la matrice des variances-covariances $\mathbf{V}$.
    \item Déterminer la matrice des corrélations $\mathbf{U}$.
    \item Calculer les valeurs propres de $\mathbf{U}$.
    \item Calculer et interpréter l'inertie expliquée des axes factoriels.
    \item Déterminer les vecteurs propres orthogonaux associés aux valeurs propres.
    \item Calculer les composantes principales.
    \item Calculer la contribution des individus et des variables.
    \item Calculer la contribution des individus à la construction des axes.
\end{enumerate}

\subsection{Solution guidée}

\subsubsection{1. Moyennes et écarts-types}

\textbf{Moyennes} :

\begin{align}
\bar{x}_1 = \frac{300 + 450 + 950 + 700}{4} = \frac{2400}{4} = 600
\end{align}

\begin{align}
\bar{x}_2 = \frac{2 + 2 + 8 + 7}{4} = \frac{19}{4} = 4.75
\end{align}

\begin{align}
\bar{x}_3 = \frac{6 + 4 + 2 + 5}{4} = \frac{17}{4} = 4.25
\end{align}

\textbf{Écarts-types} :

\begin{align}
\sigma_1 = \sqrt{\frac{1}{4}[(300-600)^2 + (450-600)^2 + (950-600)^2 + (700-600)^2]}
\end{align}

\begin{align}
= \sqrt{\frac{1}{4}[90000 + 22500 + 122500 + 10000]} = \sqrt{61250} \approx 247.49
\end{align}

\begin{align}
\sigma_2 = \sqrt{\frac{1}{4}[(2-4.75)^2 + (2-4.75)^2 + (8-4.75)^2 + (7-4.75)^2]}
\end{align}

\begin{align}
= \sqrt{\frac{1}{4}[7.5625 + 7.5625 + 10.5625 + 5.0625]} = \sqrt{7.6875} \approx 2.77
\end{align}

\begin{align}
\sigma_3 = \sqrt{\frac{1}{4}[(6-4.25)^2 + (4-4.25)^2 + (2-4.25)^2 + (5-4.25)^2]}
\end{align}

\begin{align}
= \sqrt{\frac{1}{4}[3.0625 + 0.0625 + 5.0625 + 0.5625]} = \sqrt{2.1875} \approx 1.48
\end{align}

\subsubsection{2. Matrice centrée réduite}

\begin{align}
m_{ij} = \frac{x_{ij} - \bar{x}_j}{\sigma_j}
\end{align}

\begin{align}
\mathbf{M}_{cr} = \begin{pmatrix}
\frac{300-600}{247.49} & \frac{2-4.75}{2.77} & \frac{6-4.25}{1.48} \\
\frac{450-600}{247.49} & \frac{2-4.75}{2.77} & \frac{4-4.25}{1.48} \\
\frac{950-600}{247.49} & \frac{8-4.75}{2.77} & \frac{2-4.25}{1.48} \\
\frac{700-600}{247.49} & \frac{7-4.75}{2.77} & \frac{5-4.25}{1.48}
\end{pmatrix}
= \begin{pmatrix}
-1.21 & -0.99 & 1.18 \\
-0.61 & -0.99 & -0.17 \\
1.41 & 1.17 & -1.52 \\
0.40 & 0.81 & 0.51
\end{pmatrix}
\end{align}

\subsubsection{3. Matrice des variances-covariances}

D'abord, la matrice centrée :

\begin{align}
\mathbf{M}_c = \begin{pmatrix}
-300 & -2.75 & 1.75 \\
-150 & -2.75 & -0.25 \\
350 & 3.25 & -2.25 \\
100 & 2.25 & 0.75
\end{pmatrix}
\end{align}

\begin{align}
\mathbf{V} = \frac{1}{4} \mathbf{M}_c^T \mathbf{M}_c = \begin{pmatrix}
61250 & 650 & -300 \\
650 & 7.6875 & -2.4375 \\
-300 & -2.4375 & 2.1875
\end{pmatrix}
\end{align}

\subsubsection{4. Matrice des corrélations}

\begin{align}
\mathbf{U} = \frac{1}{4} \mathbf{M}_{cr}^T \mathbf{M}_{cr} = \begin{pmatrix}
1 & 0.95 & -0.82 \\
0.95 & 1 & -0.6 \\
-0.82 & -0.6 & 1
\end{pmatrix}
\end{align}

\textbf{Interprétation} :
\begin{itemize}
    \item $r(X_1, X_2) = 0.95$ : Forte corrélation positive entre IDE et taux de croissance
    \item $r(X_1, X_3) = -0.82$ : Forte corrélation négative entre IDE et taux d'inflation
    \item $r(X_2, X_3) = -0.6$ : Corrélation négative modérée entre taux de croissance et taux d'inflation
\end{itemize}

\subsubsection{5. Valeurs propres}

Le polynôme caractéristique est :

\begin{align}
P(\lambda) = \det(\mathbf{U} - \lambda \mathbf{I}_3) = 0
\end{align}

En résolvant, on trouve :

\begin{align}
\lambda_1 = 2.57, \quad \lambda_2 = 0.43, \quad \lambda_3 = 0
\end{align}

(On ignore $\lambda_3 = 0$ car il n'apporte pas d'information)

\subsubsection{6. Inertie expliquée}

\textbf{Inertie totale} : $I_g = 3$ (car 3 variables centrées-réduites)

\textbf{Axe 1} :

\begin{align}
\text{Inertie axe 1} = \frac{\lambda_1}{\lambda_1 + \lambda_2} = \frac{2.57}{2.57 + 0.43} = \frac{2.57}{3} = 0.857 \text{ (85.7\%)}
\end{align}

\textbf{Axe 2} :

\begin{align}
\text{Inertie axe 2} = \frac{\lambda_2}{\lambda_1 + \lambda_2} = \frac{0.43}{3} = 0.143 \text{ (14.3\%)}
\end{align}

\textbf{Interprétation} : L'axe 1 contient \textbf{85.7\%} de l'information, l'axe 2 en contient \textbf{14.3\%}. Les deux premiers axes expliquent \textbf{100\%} de l'information (car $\lambda_3 = 0$).

\subsubsection{7. Vecteurs propres}

\textbf{Axe 1} ($\lambda_1 = 2.57$) :

En résolvant $\mathbf{U}\mathbf{u}_1 = 2.57\mathbf{u}_1$, on trouve :

\begin{align}
\mathbf{u}_1 = \begin{pmatrix} -0.62 \\ -0.57 \\ -0.54 \end{pmatrix}
\end{align}

\textbf{Axe 2} ($\lambda_2 = 0.43$) :

En résolvant $\mathbf{U}\mathbf{u}_2 = 0.43\mathbf{u}_2$, on trouve :

\begin{align}
\mathbf{u}_2 = \begin{pmatrix} 0.12 \\ 0.61 \\ 0.79 \end{pmatrix}
\end{align}

\subsubsection{8. Composantes principales}

\begin{align}
\mathbf{C}_1 = \mathbf{M}_{cr} \mathbf{u}_1 = \begin{pmatrix}
-1.21 & -0.99 & 1.18 \\
-0.61 & -0.99 & -0.17 \\
1.41 & 1.17 & -1.52 \\
0.40 & 0.81 & 0.51
\end{pmatrix} \begin{pmatrix} -0.62 \\ -0.57 \\ -0.54 \end{pmatrix}
= \begin{pmatrix} 0.68 \\ 1.03 \\ -0.72 \\ -0.99 \end{pmatrix}
\end{align}

\begin{align}
\mathbf{C}_2 = \mathbf{M}_{cr} \mathbf{u}_2 = \begin{pmatrix}
-1.21 & -0.99 & 1.18 \\
-0.61 & -0.99 & -0.17 \\
1.41 & 1.17 & -1.52 \\
0.40 & 0.81 & 0.51
\end{pmatrix} \begin{pmatrix} 0.12 \\ 0.61 \\ 0.79 \end{pmatrix}
= \begin{pmatrix} 0.18 \\ -0.81 \\ -0.32 \\ 0.94 \end{pmatrix}
\end{align}

\textbf{Tableau des composantes principales} :

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Pays} & $C_1$ & $C_2$ \\
\hline
A & $0.68$ & $0.18$ \\
\hline
B & $1.03$ & $-0.81$ \\
\hline
C & $-0.72$ & $-0.32$ \\
\hline
D & $-0.99$ & $0.94$ \\
\hline
\end{tabular}
\end{table}

\subsubsection{9. Contribution des individus et variables}

\textbf{Contribution des individus} :

\begin{align}
\text{CONTR}(i) = \frac{1}{np}\sum_{j=1}^{p} m_{ij}^2 = \frac{1}{4 \times 3}\sum_{j=1}^{3} m_{ij}^2
\end{align}

\begin{itemize}
    \item Pays A : $\text{CONTR}(A) = \frac{1}{12}[(-1.21)^2 + (-0.99)^2 + (1.18)^2] = \frac{1}{12}[1.464 + 0.980 + 1.392] = 0.32$
    \item Pays B : $\text{CONTR}(B) = \frac{1}{12}[(-0.61)^2 + (-0.99)^2 + (-0.17)^2] = 0.11$
    \item Pays C : $\text{CONTR}(C) = \frac{1}{12}[(1.41)^2 + (1.17)^2 + (-1.52)^2] = 0.47$
    \item Pays D : $\text{CONTR}(D) = \frac{1}{12}[(0.40)^2 + (0.81)^2 + (0.51)^2] = 0.17$
\end{itemize}

\textbf{Interprétation} : Le pays C contribue le plus (47\%) à l'analyse.

\textbf{Contribution des variables} :

\begin{align}
\text{CONTR}(X_j) = \frac{1}{p}\sum_{i=1}^{n} \frac{m_{ij}^2}{I_g} = \frac{1}{3}\sum_{i=1}^{4} \frac{m_{ij}^2}{3}
\end{align}

\begin{itemize}
    \item $X_1$ : $\text{CONTR}(X_1) = \frac{1}{9}[(1.21)^2 + (0.61)^2 + (1.41)^2 + (0.40)^2] = 0.42$
    \item $X_2$ : $\text{CONTR}(X_2) = \frac{1}{9}[(0.99)^2 + (0.99)^2 + (1.17)^2 + (0.81)^2] = 0.32$
    \item $X_3$ : $\text{CONTR}(X_3) = \frac{1}{9}[(1.18)^2 + (0.17)^2 + (1.52)^2 + (0.51)^2] = 0.33$
\end{itemize}

\textbf{Interprétation} : La variable IDE ($X_1$) contribue le plus (42\%) à l'analyse.

\subsubsection{10. Contribution des individus aux axes}

\textbf{Axe 1} :

\begin{align}
\text{CONTR}(i, \text{axe } 1) = \frac{1}{n}\frac{C_{i1}^2}{\lambda_1} = \frac{1}{4}\frac{C_{i1}^2}{2.57}
\end{align}

\begin{itemize}
    \item Pays A : $\text{CONTR}(A, \text{axe } 1) = \frac{1}{4} \times \frac{(0.68)^2}{2.57} = 0.04$
    \item Pays B : $\text{CONTR}(B, \text{axe } 1) = \frac{1}{4} \times \frac{(1.03)^2}{2.57} = 0.10$
    \item Pays C : $\text{CONTR}(C, \text{axe } 1) = \frac{1}{4} \times \frac{(-0.72)^2}{2.57} = 0.05$
    \item Pays D : $\text{CONTR}(D, \text{axe } 1) = \frac{1}{4} \times \frac{(-0.99)^2}{2.57} = 0.09$
\end{itemize}

\textbf{Axe 2} :

\begin{align}
\text{CONTR}(i, \text{axe } 2) = \frac{1}{n}\frac{C_{i2}^2}{\lambda_2} = \frac{1}{4}\frac{C_{i2}^2}{0.43}
\end{align}

\begin{itemize}
    \item Pays A : $\text{CONTR}(A, \text{axe } 2) = \frac{1}{4} \times \frac{(0.18)^2}{0.43} = 0.02$
    \item Pays B : $\text{CONTR}(B, \text{axe } 2) = \frac{1}{4} \times \frac{(-0.81)^2}{0.43} = 0.38$
    \item Pays C : $\text{CONTR}(C, \text{axe } 2) = \frac{1}{4} \times \frac{(-0.32)^2}{0.43} = 0.06$
    \item Pays D : $\text{CONTR}(D, \text{axe } 2) = \frac{1}{4} \times \frac{(0.94)^2}{0.43} = 0.51$
\end{itemize}

\textbf{Interprétation} :
\begin{itemize}
    \item Pour l'axe 1 : Le pays B contribue le plus (10\%)
    \item Pour l'axe 2 : Le pays D contribue le plus (51\%)
\end{itemize}

\newpage

\section{Interprétation des Résultats}

\subsection{Plan factoriel}

En projetant les individus sur le plan formé par les axes 1 et 2, on peut visualiser :
\begin{itemize}
    \item Les \textbf{similarités} entre pays (proximité des points)
    \item Les \textbf{oppositions} (points éloignés)
    \item Les \textbf{groupes} de pays
\end{itemize}

\subsection{Variables et axes}

Les coordonnées des variables sur les axes permettent d'interpréter :
\begin{itemize}
    \item Quelles variables contribuent le plus à chaque axe
    \item Les relations entre variables
\end{itemize}

\subsection{Critères de sélection des axes}

On retient généralement les axes qui :
\begin{itemize}
    \item Expliquent au moins 70-80\% de l'inertie totale
    \item Ont une inertie expliquée $> 1/p$ (règle de Kaiser)
    \item Permettent une interprétation claire
\end{itemize}

\newpage

\section{Résumé Final}

L'ACP est une méthode puissante pour :
\begin{itemize}
    \item \textbf{Réduire la dimension} des données
    \item \textbf{Visualiser} les relations entre individus et variables
    \item \textbf{Synthétiser} l'information contenue dans un tableau de données
    \item \textbf{Identifier} des groupes et des oppositions
\end{itemize}

Les étapes clés sont :
\begin{enumerate}
    \item Centrer et réduire les données
    \item Calculer la matrice de corrélation
    \item Extraire valeurs et vecteurs propres
    \item Calculer les composantes principales
    \item Interpréter les résultats
\end{enumerate}

\end{document}

